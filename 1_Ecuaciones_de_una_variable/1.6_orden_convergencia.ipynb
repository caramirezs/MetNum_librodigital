{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.6 Orden de convergencia de los métodos de solución de ecuaciones de una variable"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](./imagenes/colab-badge.png)](https://colab.research.google.com/github/caramirezs/MetNum_librodigital/blob/master/1_Ecuaciones_de_una_variable/1.6_orden_convergencia.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introducción\n",
    "\n",
    "Cuando se utiliza un método iterativo para resolver una ecuación de una variable, es importante conocer la velocidad con la que converge. La velocidad de convergencia se refiere a la rapidez con la que el método converge hacia la solución exacta a medida que se realizan más iteraciones. Es un criterio útil para determinar la eficiencia de un método en la solución de un problema particular.\n",
    "\n",
    "Sin embargo, la velocidad de un método iterativo no debe confundirse con el tiempo necesario para alcanzar una precisión deseada. En cambio, se refiere a la proporción en que el método converge, lo que puede representar en algunos casos la cantidad de cifras decimales que se alcanzan en cada iteración.\n",
    "\n",
    "Para entender este concepto y desarrollarlo en algunos casos especiales, es necesario presentar algunas definiciones.\n",
    "\n",
    "Definimos la convergencia de una secuencia ${x_n}$ a $L$ cuando $\\lim_{n\\to\\infty} x_n = L$. El orden de convergencia $\\alpha$ de una secuencia ${x_n}$ convergente a $L$ se define como la potencia más grande de $n$ en la expresión $|x_n - L| \\leq C n^{-\\alpha}$, donde $C$ es una constante positiva.\n",
    "\n",
    "En otras palabras, el orden de convergencia $\\alpha$ indica qué tan rápido se aproxima la secuencia ${x_n}$ a $L$ a medida que $n$ aumenta. Si $\\alpha$ es grande, entonces la secuencia converge rápidamente. Si $\\alpha$ es pequeño, la secuencia converge más lentamente.\n",
    "\n",
    "Por ejemplo, si $\\alpha = 1$, la secuencia ${x_n}$ converge linealmente a $L$. Si $\\alpha = 2$, la secuencia converge cuadráticamente a $L$. En general, cuanto mayor sea el valor de $\\alpha$, más rápida será la convergencia del método iterativo.\n",
    "\n",
    "En el contexto de los métodos numéricos para la solución de ecuaciones de una variable, el orden de convergencia de un método iterativo puede determinarse examinando la tasa de cambio del error. Por lo tanto, el orden de convergencia se puede calcular como:\n",
    "\n",
    "$$\\alpha = \\lim_{n\\rightarrow \\infty} \\dfrac{\\ln |e_{n+1}|}{\\ln |e_n|}$$\n",
    "\n",
    "Donde $e_n$ es el error en la $n$-ésima iteración. Si el límite existe y es igual a $\\alpha$, entonces decimos que el método iterativo tiene orden de convergencia $\\alpha$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Práctica\n",
    "\n",
    "Para estudiar empíricamente el orden de convergencia de los métodos abordados en este capítulo, se implementó un código en el que se modificaron los algoritmos de cada método para utilizar una tolerancia más reducida, un mayor número de iteraciones y para almacenar en una lista la secuencia de los errores absolutos de cada iteración. Además, se creó una nueva función llamada `orden_metodo`, la cual recibe como entrada la lista de errores y, a través de la fórmula recursiva $\\alpha = \\dfrac{\\ln |e_{n+1}|}{\\ln |e_n|}$, aproxima $\\alpha$ de forma iterativa. En este proceso, el valor de $n$ varía desde 0 hasta el número de iteraciones necesarias para alcanzar la solución con la precisión deseada. Este enfoque permite estimar el orden de convergencia de los métodos numéricos y comparar su eficiencia en la solución de un problema particular."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def error_biseccion(f, a, b, tol=1e-14, n=1000):\n",
    "    if not f(a) * f(b) < 0:\n",
    "        print(f'El intervalo no funciona: f({a})={f(a):.2f}, f({b})={f(b):.2f}')\n",
    "        return None\n",
    "    i, p_0 = 1, a\n",
    "    e_abs_list = []    # Lista para almacenar los errores absolutos\n",
    "    while i <= n:\n",
    "        p_i = (b + a) / 2\n",
    "        e_abs = abs(p_0 - p_i)\n",
    "        e_abs_list.append(e_abs)    # Agregar el error absoluto a la lista\n",
    "        if e_abs < tol or f(p_i) == 0:\n",
    "            return p_i, e_abs_list\n",
    "        if f(a) * f(p_i) < 0:\n",
    "            b = p_i\n",
    "        else:\n",
    "            a = p_i\n",
    "        p_0 = p_i\n",
    "        i += 1\n",
    "    else:\n",
    "        print('solución no encontrada, iteraciones agotadas')\n",
    "        return None\n",
    "\n",
    "def error_falsa_posicion(f, a, b, tol=1e-14, n=1000):\n",
    "    if not f(a) * f(b) < 0:\n",
    "        print(f'El intervalo no funciona: f({a})={f(a):.2f}, f({b})={f(b):.2f}')\n",
    "        return None\n",
    "    i, p_0 = 1, a\n",
    "    e_abs_list = []    # Lista para almacenar los errores absolutos\n",
    "    while i <= n:\n",
    "        p_i = a - (f(a) * (b - a)) / (f(b) - f(a))  # falsa posición\n",
    "        e_abs = abs(p_0 - p_i)\n",
    "        e_abs_list.append(e_abs)    # Agregar el error absoluto a la lista\n",
    "        if e_abs < tol or f(p_i) == 0:\n",
    "            return p_i, e_abs_list\n",
    "        if f(a) * f(p_i) < 0:\n",
    "            b = p_i\n",
    "        else:\n",
    "            a = p_i\n",
    "        p_0 = p_i\n",
    "        i += 1\n",
    "    else:\n",
    "        print('solución no encontrada, iteraciones agotadas')\n",
    "        return None\n",
    "\n",
    "def error_Newton_Raphson(f, df, p_0, tol=1e-14, n=1000):\n",
    "    i = 1\n",
    "    e_abs_list = []    # Lista para almacenar los errores absolutos\n",
    "    while i <= n:\n",
    "        p_i = p_0 - f(p_0)/df(p_0)  # Newton-Rapshon (recta tangente)\n",
    "        e_abs = abs(p_0 - p_i)\n",
    "        e_abs_list.append(e_abs)    # Agregar el error absoluto a la lista\n",
    "        if e_abs < tol or f(p_i) == 0:\n",
    "            return p_i, e_abs_list\n",
    "        p_0 = p_i\n",
    "        i += 1\n",
    "    else:\n",
    "        print('solución no encontrada, iteraciones agotadas')\n",
    "        return None\n",
    "\n",
    "def error_secante(f, p_00, p_0, tol=1e-14, n=1000):\n",
    "    i = 1\n",
    "    e_abs_list = []    # Lista para almacenar los errores absolutos\n",
    "    while i <= n:\n",
    "        p_i = p_0 - f(p_0)*(p_00 - p_0)/(f(p_00) - f(p_0))  # Recta secante\n",
    "        e_abs = abs(p_0 - p_i)\n",
    "        e_abs_list.append(e_abs)    # Agregar el error absoluto a la lista\n",
    "        if e_abs < tol or f(p_i) == 0:\n",
    "            return p_i, e_abs_list\n",
    "        p_0 = p_i\n",
    "        i += 1\n",
    "    else:\n",
    "        print('solución no encontrada, iteraciones agotadas')\n",
    "        return None\n",
    "\n",
    "def error_punto_fijo(g, p_0, tol=1e-14, n=100):\n",
    "    i = 1\n",
    "    e_abs_list = []    # Lista para almacenar los errores absolutos\n",
    "    while i <= n:\n",
    "        try:\n",
    "            p_i = g(p_0)\n",
    "            e_abs = abs(p_0 - p_i)\n",
    "            e_abs_list.append(e_abs)    # Agregar el error absoluto a la lista\n",
    "            if e_abs < tol or g(p_i) == p_i:\n",
    "                return p_i, e_abs_list\n",
    "            p_0 = p_i\n",
    "            i += 1\n",
    "        except OverflowError:\n",
    "            print('solución no encontrada, OverflowError')\n",
    "            return None\n",
    "        p_0 = p_i\n",
    "        i += 1\n",
    "    else:\n",
    "        print('solución no encontrada, iteraciones agotadas')\n",
    "        return None\n",
    "\n",
    "def orden_metodo(lista_error):\n",
    "    if len(lista_error) > 2:\n",
    "        order = float('inf')\n",
    "        for n in range(len(lista_error)-1):\n",
    "            if np.log(lista_error[n+1]) != 0 and np.log(lista_error[n]) != 0:\n",
    "                order = np.log(lista_error[n+1])/np.log(lista_error[n])\n",
    "        print(f\"Orden de convergencia aproximado: {order:.4f}\")\n",
    "    else:\n",
    "        print(\"No se pudo calcular el orden de convergencia.\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ejemplo\n",
    "Consideremos la ecuación $e^x - \\sin(x) = 3x^2$ que se resolvió en secciones anteriores, la cual puede ser expresada en términos de la función $f(x) = e^x - \\sin(x) - 3x^2$. Utilizando los métodos presentados en este capítulo, se encontraron las raíces de $f(x)$. A continuación, se llevará a cabo un estudio del orden de convergencia de cada método para esta ecuación."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6652670029093244\n",
      "Orden de convergencia aproximado: 1.0217\n"
     ]
    }
   ],
   "source": [
    "f = lambda x: np.e**x - np.sin(x) - 3*x**2\n",
    "sol, lista_error = error_biseccion(f, 0, 2)\n",
    "print(sol)\n",
    "orden_metodo(lista_error)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6652670029093286\n",
      "Orden de convergencia aproximado: 1.0368\n"
     ]
    }
   ],
   "source": [
    "f = lambda x: np.e**x - np.sin(x) - 3*x**2\n",
    "sol, lista_error = error_falsa_posicion(f, 0, 2)\n",
    "print(sol)\n",
    "orden_metodo(lista_error)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6652670029093302\n",
      "Orden de convergencia aproximado: 2.0310\n"
     ]
    }
   ],
   "source": [
    "f = lambda x: np.e**x - np.sin(x) - 3*x**2\n",
    "df = lambda x: np.e**x - np.cos(x) - 6*x\n",
    "sol, lista_error = error_Newton_Raphson(f, df, 0.5)\n",
    "print(sol)\n",
    "orden_metodo(lista_error)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solución: 0.6652670029093289\n",
      "Orden de convergencia aproximado: 1.0607\n"
     ]
    }
   ],
   "source": [
    "f = lambda x: np.e**x - np.sin(x) - 3*x**2\n",
    "df = lambda x: np.e**x - np.cos(x) - 6*x\n",
    "sol, lista_error = error_secante(f, 1, 0.6)\n",
    "print(f'solución: {sol}')\n",
    "orden_metodo(lista_error)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Después de aplicar los diferentes métodos para resolver la ecuación $f(x) = e^x - \\sin(x) - 3x^2$, se obtuvieron las siguientes convergencias:\n",
    "\n",
    "- **Método de Bisección**: convergencia lineal de orden 1.\n",
    "- **Método de la Secante**: convergencia lineal de orden 1.\n",
    "- **Método de la Falsa Posición**: convergencia lineal de orden 1.\n",
    "- **Método de Newton-Raphson**: convergencia cuadrática de orden 2.\n",
    "\n",
    "Es importante destacar que el orden de convergencia de un método numérico puede depender tanto de la función $f(x)$ como del punto inicial $x_0$ elegido para la iteración. Por lo tanto, es recomendable hacer un estudio detallado de cada método antes de aplicarlo en un problema en particular.\n",
    "\n",
    "El **método de Newton-Raphson** es uno de los métodos iterativos más utilizados en la solución numérica de ecuaciones no lineales debido a su alta tasa de convergencia. Se puede demostrar analíticamente que este método tiene una convergencia de orden 2, lo cual significa que la cantidad de cifras decimales correctas se duplica en cada iteración.\n",
    "\n",
    "El método de Newton-Raphson se puede demostrar que tiene una convergencia de orden 2 utilizando el desarrollo en serie de Taylor de la función $f(x)$ alrededor de la raíz $x^*$. Consideremos una raíz $x_{n+1}$ obtenida por una iteración de Newton-Raphson a partir de $x_n$:\n",
    "\n",
    "$$0 = f(x_{n+1}) = f(x_n) + f'(x_n)(x_{n+1} - x_n) + \\frac{f''(\\xi)}{2}(x_{n+1} - x_n)^2,$$\n",
    "\n",
    "donde $\\xi$ es un punto entre $x_n$ y $x_{n+1}$ y utilizamos el desarrollo en serie de Taylor de segundo orden de $f(x_{n+1})$ alrededor de $x_n$. Como $x^*$ es una raíz de la función, tenemos $f(x^*) = 0$. Restando esta igualdad de la anterior, obtenemos:\n",
    "\n",
    "$$x_{n+1} - x^* = x_n - x^* - \\frac{f(x_n)}{f'(x_n)} - \\frac{f''(\\xi)}{2f'(x_n)}(x_{n+1} - x_n)^2.$$\n",
    "\n",
    "Esta ecuación nos permite calcular el error de la aproximación en la $(n+1)$-ésima iteración en términos del error en la $n$-ésima iteración. Si $x_n$ se acerca a $x^*$, entonces $(x_n - x^*)$ es pequeño y podemos despreciar el segundo término del lado derecho de la ecuación. Luego, tomando el valor absoluto de ambos lados, obtenemos:\n",
    "\n",
    "$$|x_{n+1} - x^*| \\approx \\frac{1}{2}|x_n - x^*|^2 \\frac{|f''(\\xi)|}{|f'(x_n)|},$$\n",
    "\n",
    "donde utilizamos que $f(x_n)$ es pequeño en comparación con $f'(x_n)$ si $x_n$ es una buena aproximación a $x^*$. Esta ecuación indica que el error en la aproximación se reduce cuadráticamente en cada iteración, lo que significa que el método de Newton-Raphson tiene una convergencia de orden 2."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
